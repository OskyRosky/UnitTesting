{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Testing for Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Validation of Data Ingestion Pipelines\n",
    "\n",
    "- Description: Test that the data ingestion functions correctly read and load data from various sources.\n",
    "- Example: Verify that a data ingestion function correctly reads data from a CSV file and loads it into a database with the expected schema and content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Case 1 \n",
    "\n",
    "id,name,age\n",
    "1,Alice,30\n",
    "2,Bob,25\n",
    "3,Charlie,35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sqlite3\n",
    "\n",
    "def ingest_data(csv_file, db_conn):\n",
    "    \"\"\"\n",
    "    Reads data from a CSV file and loads it into an SQLite database.\n",
    "    \n",
    "    Args:\n",
    "    csv_file (str): Path to the CSV file.\n",
    "    db_conn (sqlite3.Connection): SQLite database connection object.\n",
    "    \"\"\"\n",
    "    cursor = db_conn.cursor()\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS users (\n",
    "            id INTEGER PRIMARY KEY,\n",
    "            name TEXT,\n",
    "            age INTEGER\n",
    "        )\n",
    "    ''')\n",
    "\n",
    "    with open(csv_file, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            cursor.execute('''\n",
    "                INSERT INTO users (id, name, age)\n",
    "                VALUES (?, ?, ?)\n",
    "            ''', (row['id'], row['name'], row['age']))\n",
    "\n",
    "    db_conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# The ingest_data function defined previously\n",
    "\n",
    "class TestDataIngestion(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        \"\"\"Set up an in-memory SQLite database and CSV file for testing.\"\"\"\n",
    "        self.db_conn = sqlite3.connect(':memory:')\n",
    "        self.csv_file = 'test_data.csv'\n",
    "        with open(self.csv_file, 'w') as file:\n",
    "            file.write('id,name,age\\n')\n",
    "            file.write('1,Alice,30\\n')\n",
    "            file.write('2,Bob,25\\n')\n",
    "            file.write('3,Charlie,35\\n')\n",
    "\n",
    "    def tearDown(self):\n",
    "        \"\"\"Clean up by closing the database connection and removing the CSV file.\"\"\"\n",
    "        self.db_conn.close()\n",
    "        os.remove(self.csv_file)\n",
    "\n",
    "    def test_ingest_data(self):\n",
    "        \"\"\"Test the data ingestion function.\"\"\"\n",
    "        ingest_data(self.csv_file, self.db_conn)\n",
    "        \n",
    "        cursor = self.db_conn.cursor()\n",
    "        cursor.execute('SELECT * FROM users')\n",
    "        rows = cursor.fetchall()\n",
    "        \n",
    "        expected_data = [\n",
    "            (1, 'Alice', 30),\n",
    "            (2, 'Bob', 25),\n",
    "            (3, 'Charlie', 35)\n",
    "        ]\n",
    "        \n",
    "        self.assertEqual(rows, expected_data)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Schema Verification\n",
    "\n",
    "- Description: Ensure that database table schemas meet the expected specifications.\n",
    "- Example: Check that all required fields are present and have the correct data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Simulate the DataFrame\n",
    "data = {\n",
    "    'id': [1, 2, 3],\n",
    "    'name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'age': [30, 25, 35]\n",
    "}\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2397856856.py, line 37)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 37\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "def create_table_from_dataframe(df, table_name, db_conn):\n",
    "    \"\"\"\n",
    "    Creates a table in the SQLite database based on the DataFrame schema.\n",
    "    \n",
    "    Args:\n",
    "    df (pd.DataFrame): The DataFrame to base the schema on.\n",
    "    table_name (str): The name of the table to create.\n",
    "    db_conn (sqlite3.Connection): SQLite database connection object.\n",
    "    \"\"\"\n",
    "    cursor = db_conn.cursor()\n",
    "    columns = ', '.join([f\"{col} {pd_to_sqlite_type(df[col].dtype)}\" for col in df.columns])\n",
    "    cursor.execute(f\"CREATE TABLE IF NOT EXISTS {table_name} ({columns})\")\n",
    "    db_conn.commit()\n",
    "\n",
    "def pd_to_sqlite_type(dtype):\n",
    "    \"\"\"\n",
    "    Maps pandas data types to SQLite data types.\n",
    "    \n",
    "    Args:\n",
    "    dtype (np.dtype): The pandas data type.\n",
    "    \n",
    "    Returns:\n",
    "    str: The corresponding SQLite data type.\n",
    "    \"\"\"\n",
    "    if pd.api.types.is_integer_dtype(dtype):\n",
    "        return \"INTEGER\"\n",
    "    elif pd.api.types.is_float_dtype(dtype):\n",
    "        return \"REAL\"\n",
    "    elif pd.api.types.is_string_dtype(dtype):\n",
    "        return \"TEXT\"\n",
    "    else:\n",
    "        return \"BLOB\"\n",
    "\n",
    "def verify_table_schema(table_name, expected_schema, db_conn):\n",
    "    \"\"\"\n",
    "    Verifies that the table schema matches the expected schema.\n",
    "    \n",
    "    Args:\n",
    "    table_name (str): The name of the table to verify.\n",
    "    expected_schema (dict): The\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# The functions defined previously\n",
    "\n",
    "class TestDataSchemaVerification(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        \"\"\"Set up an in-memory SQLite database and pandas DataFrame for testing.\"\"\"\n",
    "        self.db_conn = sqlite3.connect(':memory:')\n",
    "        self.df = pd.DataFrame({\n",
    "            'id': [1, 2, 3],\n",
    "            'name': ['Alice', 'Bob', 'Charlie'],\n",
    "            'age': [30, 25, 35]\n",
    "        })\n",
    "        self.table_name = 'users'\n",
    "        create_table_from_dataframe(self.df, self.table_name, self.db_conn)\n",
    "        self.expected_schema = {\n",
    "            'id': 'INTEGER',\n",
    "            'name': 'TEXT',\n",
    "            'age': 'INTEGER'\n",
    "        }\n",
    "\n",
    "    def tearDown(self):\n",
    "        \"\"\"Clean up by closing the database connection.\"\"\"\n",
    "        self.db_conn.close()\n",
    "\n",
    "    def test_verify_table_schema(self):\n",
    "        \"\"\"Test the schema verification function.\"\"\"\n",
    "        result = verify_table_schema(self.table_name, self.expected_schema, self.db_conn)\n",
    "        self.assertTrue(result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Integrity Check\n",
    "\n",
    "- Description: Ensure that the loaded data is not duplicated or corrupted.\n",
    "- Example: Verify that unique identifiers do not have duplicates in the target table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing Data Cleaning Functions\n",
    "\n",
    "- Description: Ensure that data cleaning functions remove or correct incorrect or incomplete data.\n",
    "- Example: Test that a function removes all rows with null values in a specific column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Automation Scripts Testing\n",
    "\n",
    "- Description: Verify that scripts automating data tasks work correctly.\n",
    "- Example: Test that an automation script uploads data files to cloud storage without errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Connection Configuration Validation\n",
    "\n",
    "- Description: Ensure that configurations for connecting to databases and other data sources are correct.\n",
    "- Example: Check that a connection function can successfully connect to a database with given credentials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Aggregation and Calculation Testing\n",
    "\n",
    "\n",
    "- Description: Verify that aggregation operations and calculations on data are correct.\n",
    "- Example: Test that a function correctly calculates the average of a numeric data column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Transformation Testing\n",
    "\n",
    "- Description: Ensure that data transformations are performed as expected.\n",
    "- Example: Verify that a function normalizes values in a column to a specific range.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. File Format Validation\n",
    "\n",
    "- Description: Ensure that data files comply with expected formats.\n",
    "- Example: Test that a function exports data in CSV format with the correct delimiter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Data Transfer Integrity Check\n",
    "\n",
    "- Description: Verify that data transferred between systems is not lost or corrupted.\n",
    "- Example: Test that the number of records in the source and destination systems is the same after the transfer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Testing for a Data Scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
